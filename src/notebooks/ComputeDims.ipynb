{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d99277d-f0d5-4254-ba7a-03c735859cb4",
   "metadata": {},
   "source": [
    "# Compute Dims for LSTM/CNN Models\n",
    "\n",
    "Helper functions to computer the correct dimension needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Some fake X input of dimension (100 samples, 1 channel, 1999 length)\n",
    "X = torch.FloatTensor(np.ones((64,48,390)))\n",
    "\n",
    "# init parameters\n",
    "input_channels = 48\n",
    "\n",
    "# First conv layer parameters\n",
    "out_channels_conv1 = 100 # number of kernels\n",
    "Conv1_padding = 0\n",
    "Conv1_dilation = 1\n",
    "Conv1_kernel_size = 2\n",
    "Conv1_stride = 1\n",
    "\n",
    "# MasPool parameters\n",
    "MaxPool_kernel_size = 3\n",
    "MaxPool_stride = 3\n",
    "MaxPool_padding = 0\n",
    "MaxPool_dilation = 1\n",
    "\n",
    "input_size = X.shape[2]\n",
    "\n",
    "# first conv layer\n",
    "conv1 = torch.nn.Conv1d(input_channels, out_channels_conv1, Conv1_kernel_size, stride=Conv1_stride, padding = Conv1_padding)\n",
    "out1 = conv1(X)\n",
    "\n",
    "# calculating the output size of Conv1 with the formula from Pytorch docs\n",
    "L_out = ((input_size + 2*Conv1_padding - Conv1_dilation*(Conv1_kernel_size-1) -1)/Conv1_stride +1)\n",
    "if int(L_out) == out1.shape[2]:\n",
    "  print(\"Length at output of conv1 equals calculated length so everything looks good.\\n Now pushing output of conv1 in MaxPool1d...\")\n",
    "  \n",
    "# Now pushing data through MaxPool1d\n",
    "MP1 = torch.nn.MaxPool1d(MaxPool_kernel_size,stride=MaxPool_stride)\n",
    "out2 = MP1(out1)\n",
    "print(\"Observed length is {}\".format(out2.shape[2]))\n",
    "Lout2 = np.floor((L_out+2*MaxPool_padding-MaxPool_dilation*(MaxPool_kernel_size-1)-1)/MaxPool_stride+1)\n",
    "print(\"Calculated length with Pytorch doc is {}\".format(Lout2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d15377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "#from sklearn import metrics\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class LSTM_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=390, hidden_dim=8, lstm_layers=1, bidirectional=False, dense=False):\n",
    "\n",
    "        #dim, batch_norm, dropout, rec_dropout, task,\n",
    "        #target_repl = False, deep_supervision = False, num_classes = 1,\n",
    "        #depth = 1, input_dim = 390, ** kwargs\n",
    "\n",
    "        super(LSTM_CNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = lstm_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dense = dense\n",
    "\n",
    "        # some more parameters\n",
    "        self.output_dim = dim\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout = dropout\n",
    "        self.rec_dropout = rec_dropout\n",
    "        self.depth = depth\n",
    "        self.dropout_words = 0.3\n",
    "        self.dropout_rnn_U = 0.3\n",
    "        self.drop_conv = 0.5\n",
    "\n",
    "        # define the LSTM layer\n",
    "        # in keras we have inputs: A 3D tensor with shape [batch, timesteps, feature]\n",
    "        # units: Positive integer, dimensionality of the output space. = dim=num_units=hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=self.input_dim,\n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.layers,\n",
    "                            dropout=self.rec_dropout,\n",
    "                            bidirectional=self.bidirectional)\n",
    "\n",
    "        # this is not in the original model\n",
    "        self.act1 = nn.ReLU()\n",
    "\n",
    "        self.do1 = nn.Dropout(self.dropout)\n",
    "        self.cnn = nn.Conv1d()\n",
    "        # concat the three outputs from the CNN\n",
    "        self.do2 = nn.Dropout(self.drop_conv)\n",
    "        self.dense = nn.Linear(self.hidden_dim, self.num_classes)\n",
    "\n",
    "        # change linear layer inputs depending on if lstm is bidrectional and extra dense layer isn't added\n",
    "        if bidirectional and not dense:\n",
    "            self.final = nn.Linear(self.hidden_dim * 2, 1)\n",
    "        else:\n",
    "            self.final = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        out = inputs.unsqueeze(1)\n",
    "        out, h = self.lstm(out)\n",
    "        out = self.act1(out)\n",
    "        #if self.dense:\n",
    "        #    out = self.linear(out)\n",
    "        #    out = self.act2(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class LSTM_CNN2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=390, hidden_dim=8, lstm_layers=1):\n",
    "\n",
    "        #dim, batch_norm, dropout, rec_dropout, task,\n",
    "        #target_repl = False, deep_supervision = False, num_classes = 1,\n",
    "        #depth = 1, input_dim = 390, ** kwargs\n",
    "\n",
    "        super(LSTM_CNN2, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = lstm_layers\n",
    "        self.bidirectional = True\n",
    "        #self.dense = dense\n",
    "\n",
    "        # some more parameters\n",
    "        #self.output_dim = dim\n",
    "        #self.batch_norm = batch_norm\n",
    "        self.dropout = 0.3\n",
    "        self.rec_dropout = 0.3\n",
    "        self.depth = lstm_layers\n",
    "        self.drop_conv = 0.5\n",
    "        self.num_classes = 1\n",
    "\n",
    "        # define the LSTM layer\n",
    "        # in keras we have inputs: A 3D tensor with shape [batch, timesteps, feature]\n",
    "        # units: Positive integer, dimensionality of the output space. = dim=num_units=hidden_size\n",
    "        if self.layers >=2:\n",
    "            self.lstm1 = nn.LSTM(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim,\n",
    "                                num_layers=self.layers-1,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=self.bidirectional,\n",
    "                                batch_first=True)\n",
    "            self.do0 = nn.Dropout(self.dropout)\n",
    "            \n",
    "        # this is not in the original model\n",
    "        #self.act1 = nn.ReLU()\n",
    "        if self.layers >=2:\n",
    "            self.lstm2 = nn.LSTM(input_size=self.hidden_dim*2,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "        else:\n",
    "            self.lstm2 = nn.LSTM(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "\n",
    "        self.do1 = nn.Dropout(self.dropout)\n",
    "        #self.bn0 = nn.BatchNorm1d(48 * self.hidden_dim*2)\n",
    "        \n",
    "        # three Convolutional Neural Networks with different kernel sizes\n",
    "        nfilters=[2, 3, 4]\n",
    "        nb_filters=100\n",
    "        pooling_reps = []\n",
    "            \n",
    "        self.cnn1 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=2,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=3,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn3 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=4,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.do2 = nn.Dropout(self.drop_conv)\n",
    "        self.final = nn.Linear(6800, self.num_classes)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        out = inputs\n",
    "        if self.layers >=2:\n",
    "            out, h = self.lstm1(out)\n",
    "            out = self.do0(out)\n",
    "        out, h = self.lstm2(out)\n",
    "        out = self.do1(out)\n",
    "\n",
    "        pooling_reps = []\n",
    "        \n",
    "        pool_vecs = self.cnn1(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn2(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn3(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "            \n",
    "        # concatenate all vectors\n",
    "        representation = torch.cat(pooling_reps, dim=1).contiguous()\n",
    "        out = self.do2(representation)\n",
    "        out = self.final(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "\n",
    "class MCDualMixin:\n",
    "    \"\"\"Monte Carlo mixin\n",
    "    This mixin provide a method `sample` to sample from defined model\n",
    "    Use this Mixin by inheriting this class\n",
    "    Assuming that model returns a tuple of 2 tensors\"\"\"\n",
    "\n",
    "    def get_output_shape(self, *args):\n",
    "        \"Override this to get output dimensions.\"\n",
    "        raise NotImplementedError(\"Need to define output shape\")\n",
    "    \n",
    "    def sample(self, T:int, *args):\n",
    "        # Construct empty outputs\n",
    "        shape_m, shape_v = self.get_output_shape(*args)\n",
    "        M, V = torch.empty(T, *shape_m), torch.empty(T, *shape_v)\n",
    "        \n",
    "        for t in range(T):\n",
    "            M[t], V[t] = self(*args)\n",
    "        \n",
    "        return M, V\n",
    "\n",
    "\n",
    "class MCSingleMixin:\n",
    "    \"\"\"Monte Carlo mixin\n",
    "    This mixin provide a method `sample` to sample from defined model\n",
    "    Use this Mixin by inheriting this class\n",
    "    Assuming that model returns a single tensors\"\"\"\n",
    "\n",
    "    def get_output_shape(self, *args):\n",
    "        \"Override this to get output dimensions.\"\n",
    "        raise NotImplementedError(\"Need to define output shape\")\n",
    "    \n",
    "    def sample(self, T:int, *args):\n",
    "        # Construct empty outputs\n",
    "        shape_m = self.get_output_shape(*args)\n",
    "        M = torch.empty(T, *shape_m)\n",
    "        \n",
    "        for t in range(T):\n",
    "            M[t] = self(*args)\n",
    "        \n",
    "        return M\n",
    "\n",
    "\n",
    "\n",
    "class StochasticLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, dropout: Optional[float]=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - dropout: should be between 0 and 1\n",
    "        \"\"\"\n",
    "        super(StochasticLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if dropout is None:\n",
    "            self.p_logit = nn.Parameter(torch.empty(1).normal_())\n",
    "        elif not 0 < dropout < 1:\n",
    "            raise Exception(\"Dropout rate should be between in (0, 1)\")\n",
    "        else:\n",
    "            self.p_logit = dropout\n",
    "\n",
    "        self.Wi = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.Wf = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.Wo = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.Wg = nn.Linear(self.input_size, self.hidden_size)\n",
    "        \n",
    "        self.Ui = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.Uf = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.Uo = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.Ug = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        k = torch.tensor(self.hidden_size, dtype=torch.float32).reciprocal().sqrt()\n",
    "        \n",
    "        self.Wi.weight.data.uniform_(-k,k)\n",
    "        self.Wi.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Wf.weight.data.uniform_(-k,k)\n",
    "        self.Wf.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Wo.weight.data.uniform_(-k,k)\n",
    "        self.Wo.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Wg.weight.data.uniform_(-k,k)\n",
    "        self.Wg.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Ui.weight.data.uniform_(-k,k)\n",
    "        self.Ui.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Uf.weight.data.uniform_(-k,k)\n",
    "        self.Uf.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Uo.weight.data.uniform_(-k,k)\n",
    "        self.Uo.bias.data.uniform_(-k,k)\n",
    "        \n",
    "        self.Ug.weight.data.uniform_(-k,k)\n",
    "        self.Ug.bias.data.uniform_(-k,k)\n",
    "        \n",
    "    # Note: value p_logit at infinity can cause numerical instability\n",
    "    def _sample_mask(self, B):\n",
    "        \"\"\"Dropout masks for 4 gates, scale input by 1 / (1 - p)\"\"\"\n",
    "        if isinstance(self.p_logit, float):\n",
    "            p = self.p_logit\n",
    "        else:\n",
    "            p = torch.sigmoid(self.p_logit)\n",
    "        GATES = 4\n",
    "        eps = torch.tensor(1e-7)\n",
    "        t = 1e-1\n",
    "        \n",
    "        ux = torch.rand(GATES, B, self.input_size)\n",
    "        uh = torch.rand(GATES, B, self.hidden_size)\n",
    "\n",
    "        if self.input_size == 1:\n",
    "            zx = (1-torch.sigmoid((torch.log(eps) - torch.log(1+eps)\n",
    "                                   + torch.log(ux+eps) - torch.log(1-ux+eps))\n",
    "                                 / t))\n",
    "        else:\n",
    "            zx = (1-torch.sigmoid((torch.log(p+eps) - torch.log(1-p+eps)\n",
    "                                   + torch.log(ux+eps) - torch.log(1-ux+eps))\n",
    "                                 / t)) / (1-p)\n",
    "        zh = (1-torch.sigmoid((torch.log(p+eps) - torch.log(1-p+eps)\n",
    "                               + torch.log(uh+eps) - torch.log(1-uh+eps))\n",
    "                             / t)) / (1-p)\n",
    "        return zx, zh\n",
    "\n",
    "    def regularizer(self):        \n",
    "        if isinstance(self.p_logit, float):\n",
    "            p = torch.tensor(self.p_logit)\n",
    "        else:\n",
    "            p = torch.sigmoid(self.p_logit)\n",
    "        \n",
    "        # Weight\n",
    "        weight_sum = torch.tensor([\n",
    "            torch.sum(params**2) for name, params in self.named_parameters() if name.endswith(\"weight\")\n",
    "        ]).sum() / (1.-p)\n",
    "        \n",
    "        # Bias\n",
    "        bias_sum = torch.tensor([\n",
    "            torch.sum(params**2) for name, params in self.named_parameters() if name.endswith(\"bias\")\n",
    "        ]).sum()\n",
    "        \n",
    "        if isinstance(self.p_logit, float):\n",
    "            dropout_reg = torch.zeros(1)\n",
    "        else:\n",
    "             # Dropout\n",
    "            dropout_reg = self.input_size * (p * torch.log(p) + (1-p)*torch.log(1-p))\n",
    "        return weight_sum, bias_sum, 2.*dropout_reg\n",
    "        \n",
    "    def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]=None) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:\n",
    "        \"\"\"\n",
    "        input shape (sequence, batch, input dimension)\n",
    "        output shape (sequence, batch, output dimension)\n",
    "        return output, (hidden_state, cell_state)\n",
    "        \"\"\"\n",
    "\n",
    "        T, B = input.shape[0:2]\n",
    "\n",
    "        if hx is None:\n",
    "            h_t = torch.zeros(B, self.hidden_size, dtype=input.dtype)\n",
    "            c_t = torch.zeros(B, self.hidden_size, dtype=input.dtype)\n",
    "        else:\n",
    "            h_t, c_t = hx\n",
    "\n",
    "        hn = torch.empty(T, B, self.hidden_size, dtype=input.dtype)\n",
    "\n",
    "        # Masks\n",
    "        zx, zh = self._sample_mask(B)\n",
    "        \n",
    "        for t in range(T):\n",
    "            x_i, x_f, x_o, x_g = (input[t] * zx_ for zx_ in zx)\n",
    "            h_i, h_f, h_o, h_g = (h_t * zh_ for zh_ in zh)\n",
    "\n",
    "            i = torch.sigmoid(self.Ui(h_i) + self.Wi(x_i))\n",
    "            f = torch.sigmoid(self.Uf(h_f) + self.Wf(x_f))\n",
    "            o = torch.sigmoid(self.Uo(h_o) + self.Wo(x_o))\n",
    "            g = torch.tanh(self.Ug(h_g) + self.Wg(x_g))\n",
    "\n",
    "            c_t = f * c_t + i * g\n",
    "            h_t = o * torch.tanh(c_t)\n",
    "            hn[t] = h_t\n",
    "        \n",
    "        return hn, (h_t, c_t)\n",
    "\n",
    "\n",
    "class StochasticLSTM(nn.Module):\n",
    "    \"\"\"LSTM stacked layers with dropout and MCMC\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, dropout:Optional[float]=None, num_layers: int=1):\n",
    "        super(StochasticLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.first_layer = StochasticLSTMCell(input_size, hidden_size, dropout)\n",
    "        self.hidden_layers = nn.ModuleList([StochasticLSTMCell(hidden_size, hidden_size, dropout) for i in range(num_layers-1)])\n",
    "    \n",
    "    def regularizer(self):\n",
    "        total_weight_reg, total_bias_reg, total_dropout_reg = self.first_layer.regularizer()\n",
    "        for l in self.hidden_layers:\n",
    "            weight, bias, dropout = l.regularizer()\n",
    "            total_weight_reg += weight\n",
    "            total_bias_reg += bias\n",
    "            total_dropout_reg += dropout\n",
    "        return total_weight_reg, total_bias_reg, total_dropout_reg\n",
    "\n",
    "    def forward(self, input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]=None) -> Tuple[Tensor, Tuple[Tensor, Tensor]]:\n",
    "        B = input.shape[1]\n",
    "        h_n = torch.empty(self.num_layers, B, self.first_layer.hidden_size)\n",
    "        c_n = torch.empty(self.num_layers, B, self.first_layer.hidden_size)\n",
    "        \n",
    "        outputs, (h, c) = self.first_layer(input, hx)\n",
    "        h_n[0] = h\n",
    "        c_n[0] = c\n",
    "\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            outputs, (h, c) = layer(outputs, (h, c))\n",
    "            h_n[i+1] = h\n",
    "            c_n[i+1] = c\n",
    "\n",
    "        return outputs, (h_n, c_n)\n",
    "        \n",
    "        \n",
    "class LSTM_CNN3(nn.Module, MCSingleMixin):\n",
    "    \n",
    "    def __init__(self, input_dim=390, hidden_dim=8, lstm_layers=1):\n",
    "\n",
    "        super(LSTM_CNN3, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = lstm_layers\n",
    "        self.bidirectional = True\n",
    "\n",
    "        # some more parameters\n",
    "        self.dropout = 0.3\n",
    "        self.rec_dropout = 0.3\n",
    "        self.depth = lstm_layers\n",
    "        self.drop_conv = 0.5\n",
    "        self.num_classes = 1\n",
    "\n",
    "        # define the LSTM layer\n",
    "        # in keras we have inputs: A 3D tensor with shape [batch, timesteps, feature]\n",
    "        # units: Positive integer, dimensionality of the output space. = dim=num_units=hidden_size\n",
    "\n",
    "        self.lstm1 = StochasticLSTM(input_size=self.input_dim,\n",
    "                            hidden_size=self.hidden_dim*2,\n",
    "                            dropout=self.rec_dropout,\n",
    "                            num_layers=self.layers)\n",
    "        self.do0 = nn.Dropout(self.dropout)\n",
    "        \n",
    "        # three Convolutional Neural Networks with different kernel sizes\n",
    "        nfilters=[2, 3, 4]\n",
    "        nb_filters=100\n",
    "        pooling_reps = []\n",
    "            \n",
    "        self.cnn1 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=2,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=3,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn3 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=4,\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.do2 = nn.Dropout(self.drop_conv)\n",
    "        self.final = nn.Linear(6800, self.num_classes)\n",
    "\n",
    "    def regularizer(self):\n",
    "        # Weight and bias regularizer\n",
    "        weight_sum, bias_sum, dropout_reg = self.lstm1.regularizer()\n",
    "        \n",
    "        return weight_sum + bias_sum + dropout_reg\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        out = inputs.permute((1,0,2)) # 0,1,2 -> 1,0,2\n",
    "        out, h = self.lstm1(out)\n",
    "        out = self.do0(out)\n",
    "        out = out.permute((1,0,2))\n",
    "        \n",
    "        pooling_reps = []\n",
    "        \n",
    "        pool_vecs = self.cnn1(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn2(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn3(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "            \n",
    "        # concatenate all vectors\n",
    "        representation = torch.cat(pooling_reps, dim=1).contiguous()\n",
    "        out = self.do2(representation)\n",
    "        out = self.final(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class VariationalDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies the same dropout mask across the temporal dimension\n",
    "    See https://arxiv.org/abs/1512.05287 for more details.\n",
    "    Note that this is not applied to the recurrent activations in the LSTM like the above paper.\n",
    "    Instead, it is applied to the inputs and outputs of the recurrent layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout: float, batch_first: Optional[bool]=False):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training or self.dropout <= 0.:\n",
    "            return x\n",
    "\n",
    "        is_packed = isinstance(x, PackedSequence)\n",
    "        if is_packed:\n",
    "            x, batch_sizes = x\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = x.size(0)\n",
    "\n",
    "        # Drop same mask across entire sequence\n",
    "        if self.batch_first:\n",
    "            m = x.new_empty(max_batch_size, 1, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        else:\n",
    "            m = x.new_empty(1, max_batch_size, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        x = x.masked_fill(m == 0, 0) / (1 - self.dropout)\n",
    "\n",
    "        if is_packed:\n",
    "            return PackedSequence(x, batch_sizes)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class LSTMNew(nn.LSTM):\n",
    "    def __init__(self, *args, dropouti: float=0.,\n",
    "                 dropoutw: float=0., dropouto: float=0.,\n",
    "                 batch_first=True, unit_forget_bias=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs, batch_first=batch_first)\n",
    "        self.unit_forget_bias = unit_forget_bias\n",
    "        self.dropoutw = dropoutw\n",
    "        self.input_drop = VariationalDropout(dropouti,\n",
    "                                             batch_first=batch_first)\n",
    "        self.output_drop = VariationalDropout(dropouto,\n",
    "                                              batch_first=batch_first)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Use orthogonal init for recurrent layers, xavier uniform for input layers\n",
    "        Bias is 0 except for forget gate\n",
    "        \"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif \"bias\" in name and self.unit_forget_bias:\n",
    "                nn.init.zeros_(param.data)\n",
    "                param.data[self.hidden_size:2 * self.hidden_size] = 1\n",
    "\n",
    "    def _drop_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                getattr(self, name).data = \\\n",
    "                    torch.nn.functional.dropout(param.data, p=self.dropoutw,\n",
    "                                                training=self.training).contiguous()\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        self._drop_weights()\n",
    "        self.flatten_parameters() \n",
    "        input = self.input_drop(input)\n",
    "        seq, state = super().forward(input, hx=hx)\n",
    "        return self.output_drop(seq), state\n",
    "\n",
    "\n",
    "class LSTM_CNN4(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=390, hidden_dim=8, lstm_layers=1, dropout=0.3, dropout_w=0.3, dropout_conv=0.5):\n",
    "\n",
    "        #dim, batch_norm, dropout, rec_dropout, task,\n",
    "        #target_repl = False, deep_supervision = False, num_classes = 1,\n",
    "        #depth = 1, input_dim = 390, ** kwargs\n",
    "\n",
    "        super(LSTM_CNN4, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = lstm_layers\n",
    "        self.bidirectional = True\n",
    "\n",
    "        # some more parameters\n",
    "        self.dropout = dropout\n",
    "        self.rec_dropout = dropout_w\n",
    "        self.depth = lstm_layers\n",
    "        self.drop_conv = dropout_conv\n",
    "        self.num_classes = 1\n",
    "\n",
    "        # define the LSTM layer\n",
    "        # in keras we have inputs: A 3D tensor with shape [batch, timesteps, feature]\n",
    "        # units: Positive integer, dimensionality of the output space. = dim=num_units=hidden_size\n",
    "        if self.layers >=2:\n",
    "            self.lstm1 = LSTMNew(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim,\n",
    "                                num_layers=self.layers-1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=self.bidirectional,\n",
    "                                batch_first=True)\n",
    "            self.do0 = nn.Dropout(self.dropout)\n",
    "            \n",
    "        # this is not in the original model\n",
    "        if self.layers >=2:\n",
    "            self.lstm2 = LSTMNew(input_size=self.hidden_dim*2,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "        else:\n",
    "            self.lstm2 = LSTMNew(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "        \n",
    "        # three Convolutional Neural Networks with different kernel sizes\n",
    "        nfilters=[3, 4, 5]\n",
    "        nb_filters=100\n",
    "        pooling_reps = []\n",
    "        \n",
    "        L_out = [(48 - k) + 1 for k in nfilters]\n",
    "        MaxPool_padding = 0\n",
    "        MaxPool_dilation = 1\n",
    "        MaxPool_kernel_size = 2\n",
    "        MaxPool_stride = 2\n",
    "\n",
    "        dim_ = int(np.sum([100*np.floor((l + 2 * MaxPool_padding - MaxPool_dilation * (MaxPool_kernel_size-1) - 1)/MaxPool_stride + 1) for l in L_out]))\n",
    "\n",
    "        print(f'{dim_=}')\n",
    "        self.cnn1 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=nfilters[0],\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=nfilters[1],\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.cnn3 = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=nfilters[2],\n",
    "                          stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                          padding_mode='zeros'),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        \n",
    "        self.do2 = nn.Dropout(self.drop_conv)\n",
    "        self.final = nn.Linear(dim_, self.num_classes)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        out = inputs\n",
    "        print(f'{out.shape=}')\n",
    "        if self.layers >=2:\n",
    "            out, h = self.lstm1(out)\n",
    "            out = self.do0(out)\n",
    "            print(f'{out.shape=}')\n",
    "        out, h = self.lstm2(out)\n",
    "        print(f'{out.shape=}')\n",
    "        \n",
    "        pooling_reps = []\n",
    "        \n",
    "        pool_vecs = self.cnn1(out.permute((0,2,1)))\n",
    "        print(f'{pool_vecs.shape=}')\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn2(out.permute((0,2,1)))\n",
    "        print(f'{pool_vecs.shape=}')\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn3(out.permute((0,2,1)))\n",
    "        print(f'{pool_vecs.shape=}')\n",
    "        pooling_reps.append(pool_vecs)\n",
    "            \n",
    "        # concatenate all vectors\n",
    "        representation = torch.cat(pooling_reps, dim=1).contiguous()\n",
    "        print(f'{representation.shape=}')\n",
    "        out = self.do2(representation)\n",
    "        print(f'{out.shape=}')\n",
    "        out = self.final(out)\n",
    "        print(f'{out.shape=}')\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bff9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_CNN4(hidden_dim=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_out = 45\n",
    "MaxPool_padding = 0\n",
    "MaxPool_dilation = 1\n",
    "MaxPool_kernel_size = 2\n",
    "MaxPool_stride = 2\n",
    "\n",
    "np.floor((L_out + 2 * MaxPool_padding - MaxPool_dilation * (MaxPool_kernel_size-1) - 1)/MaxPool_stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d14062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
