{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUymE2l9GZfO"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "JMyTNwSJGGWg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# Universal Sentence Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/s?q=google%2Funiversal-sentence-encoder%2F4%20OR%20google%2Funiversal-sentence-encoder-large%2F5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVjNK8shFKOC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwty8Z6mAkdV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Load the Universal Sentence Encoder's TF Hub module\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8F4LNGFqOiq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Compute a representation for each message, showing various lengths supported.\n",
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "message_embeddings = embed(messages)\n",
    "\n",
    "for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "  print(\"Message: {}\".format(messages[i]))\n",
    "  print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "  message_embedding_snippet = \", \".join(\n",
    "      (str(x) for x in message_embedding[:3]))\n",
    "  print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJdt37ovgZqH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.inner(message_embeddings, message_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnvjATdy64eR"
   },
   "source": [
    "# Semantic Textual Similarity Task Example\n",
    "\n",
    "The embeddings produced by the Universal Sentence Encoder are approximately normalized. The semantic similarity of two sentences can be trivially computed as the inner product of the encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1FFCTKm7ba4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation, print_labels=True):\n",
    "  corr = np.inner(features, features)\n",
    "  labels = [m[:25] + '/' + str(len(m)) for m in labels]\n",
    "  sns.set(rc = {'figure.figsize':(20,12)})\n",
    "  sns.set(font_scale=1.2)\n",
    "  g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      annot=print_labels, fmt='.1f',\n",
    "      cmap=\"YlOrRd\")\n",
    "  g.set_xticklabels(labels, rotation=rotation)\n",
    "  g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "def run_and_plot(messages_):\n",
    "  message_embeddings_ = embed(messages_)\n",
    "  plot_similarity(messages_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "# length 250\n",
    "\"What is a color or a friend.\",\n",
    "\"This house has a big room and some small rooms.\",\n",
    "\"My father was a rolling stone.\",\n",
    "\"My father is a good guy.\",\n",
    "\"When I get older.\",\n",
    "\"When I was younger.\"\n",
    "]\n",
    "\n",
    "run_and_plot(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FjdeCqPJeg-"
   },
   "source": [
    "## Evaluation: STS (Semantic Textual Similarity) Benchmark\n",
    "\n",
    "The [**STS Benchmark**](https://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) provides an intrinsic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5nuBbI1iFQR"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOs8ZfOnJeBF"
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "# import scipy\n",
    "# import math\n",
    "# import csv\n",
    "\n",
    "# sts_dataset = tf.keras.utils.get_file(\n",
    "#     fname=\"Stsbenchmark.tar.gz\",\n",
    "#     origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "#     extract=True)\n",
    "# sts_dev = pandas.read_table(\n",
    "#     os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"),\n",
    "#     error_bad_lines=False,\n",
    "#     skip_blank_lines=True,\n",
    "#     usecols=[4, 5, 6],\n",
    "#     names=[\"sim\", \"sent_1\", \"sent_2\"])\n",
    "# sts_test = pandas.read_table(\n",
    "#     os.path.join(\n",
    "#         os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"),\n",
    "#     error_bad_lines=False,\n",
    "#     quoting=csv.QUOTE_NONE,\n",
    "#     skip_blank_lines=True,\n",
    "#     usecols=[4, 5, 6],\n",
    "#     names=[\"sim\", \"sent_1\", \"sent_2\"])\n",
    "# # cleanup some NaN values in sts_dev\n",
    "# sts_dev = sts_dev[[isinstance(s, str) for s in sts_dev['sent_2']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OKy8WhnKRe_"
   },
   "source": [
    "### Evaluate Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-q2r7jyZGb7"
   },
   "outputs": [],
   "source": [
    "# sts_data = sts_dev #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\n",
    "\n",
    "# def run_sts_benchmark(batch):\n",
    "#   sts_encode1 = tf.nn.l2_normalize(embed(tf.constant(batch['sent_1'].tolist())), axis=1)\n",
    "#   sts_encode2 = tf.nn.l2_normalize(embed(tf.constant(batch['sent_2'].tolist())), axis=1)\n",
    "#   cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "#   clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n",
    "#   scores = 1.0 - tf.acos(clip_cosine_similarities) / math.pi\n",
    "#   \"\"\"Returns the similarity scores\"\"\"\n",
    "#   return scores\n",
    "\n",
    "# dev_scores = sts_data['sim'].tolist()\n",
    "# scores = []\n",
    "# for batch in np.array_split(sts_data, 10):\n",
    "#   scores.extend(run_sts_benchmark(batch))\n",
    "\n",
    "# pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
    "# print('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
    "#     pearson_correlation[0], pearson_correlation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0EkOMAa9xQZ"
   },
   "outputs": [],
   "source": [
    "# !pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6powUQjBUySZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#checkpoint = \"allenai/longformer-base-4096\"\n",
    "#checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "#checkpoint = \"dmis-lab/biobert-large-cased-v1.1\"\n",
    "#checkpoint = \"mrm8488/longformer-base-4096-finetuned-squadv2\"\n",
    "#checkpoint = \"johngiorgi/declutr-small\"\n",
    "checkpoint = \"johngiorgi/declutr-base\"\n",
    "#checkpoint = \"johngiorgi/declutr-sci-base\"\n",
    "#checkpoint = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKon1o5fVi0G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"my father was a Rolling Stone\"*100\n",
    "inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6H4AAYVV-Dt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M85ckT2sXmVg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0BDC0-AXcIP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs['last_hidden_state'][:,7,:].shape #, outputs['pooler_output'].shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyxYiHLclHYj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#outputs['last_hidden_state'][:,-1,:] == outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URsAHcGKWl_8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def embed_trsf(messages):\n",
    "    inputs = tokenizer(messages, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    #print(inputs)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    try:\n",
    "        embed_trsf = outputs.pooler_output\n",
    "        return torch.nn.functional.normalize(embed_trsf.detach()).numpy()\n",
    "    except:\n",
    "        embed_trsf = outputs.last_hidden_state # pooler_output\n",
    "        return torch.nn.functional.normalize(embed_trsf[:, 0, :].detach()).numpy()\n",
    "\n",
    "def run_and_plot_trsf(messages_):\n",
    "  message_embeddings_ = embed_trsf(messages_)\n",
    "  plot_similarity(messages_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmzA1vs2YV6h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = [\"We found him on the floor in a critical state\"]\n",
    "\n",
    "inputs = tokenizer(m, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "\"What is a color or a friend.\",\n",
    "\"This house has a big room and some small rooms.\",\n",
    "\"My father was a rolling stone.\",\n",
    "\"My father is a good guy.\",\n",
    "\"When I get older.\",\n",
    "\"When I was younger.\"\n",
    "]\n",
    "\n",
    "run_and_plot_trsf(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "sentence_embeddings = model.encode(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_and_plot_se(messages_, print_labels=True):\n",
    "    message_embeddings_ = model.encode(messages_)\n",
    "    plot_similarity(messages_, message_embeddings_, 90, print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "\"What is a color or a friend.\",\n",
    "\"This house has a big room and some small rooms.\",\n",
    "\"My father was a rolling stone.\",\n",
    "\"My father is a good guy.\",\n",
    "\"When I get older.\",\n",
    "\"When I was younger.\"\n",
    "]\n",
    "\n",
    "run_and_plot_se(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "run_and_plot_se(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "import torch.nn as nn\n",
    "#word_embedding_model = models.Transformer('bert-base-uncased')\n",
    "word_embedding_model = models.Transformer('jamesmullenbach/CLIP_DNote_BERT_Context')\n",
    "\n",
    "tokens = [\"[DOC]\", \"[QRY]\"]\n",
    "word_embedding_model.tokenizer.add_tokens(tokens, special_tokens=True)\n",
    "word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n",
    "\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=1024, activation_function=nn.Tanh())\n",
    "normalizer = models.Normalize()\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model, normalizer])\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df = pickle.load(open('/Users/jplasser/Documents/AI Master/WS2021/MastersThesis/code.nosync/CNEP/src/data/mimic3/full_train_data_unique.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes = df['notes']\n",
    "messages = []\n",
    "no_messages = 50\n",
    "\n",
    "for i in range(no_messages):\n",
    "    messages.append(f'\"{notes[i][:200]}\",')\n",
    "    \n",
    "run_and_plot_se(messages, print_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# experimental\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "word_embedding_model = model._modules['0']\n",
    "pooling_model = model._modules['1']\n",
    "normalize_model = model._modules['2']\n",
    "\n",
    "#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=1024, activation_function=nn.Tanh())\n",
    "#normalizer = models.Normalize()\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model, normalizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('../models/pretrained_sentence_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model._modules['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model=\"abc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for m in word_embedding_model.modules():\n",
    "#     print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_sentence_transformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentenceTransformer Model used in Master Thesis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from torch import nn\n",
    "\n",
    "# 'microsoft/mpnet-base'\n",
    "word_embedding_model = models.Transformer('sentence-transformers/all-mpnet-base-v2', max_seq_length=384)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=1024,\n",
    "                           activation_function=nn.Tanh())\n",
    "\n",
    "normalize_model = models.Normalize()\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model, normalize_model])\n",
    "\n",
    "# freeze transformer layers of the model\n",
    "auto_model = model._first_module().auto_model\n",
    "for param in auto_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from torch import nn\n",
    "\n",
    "# clinical BERT model embeddings\n",
    "word_embedding_model = models.Transformer('emilyalsentzer/Bio_ClinicalBERT', max_seq_length=384)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=15000,\n",
    "                           activation_function=nn.ReLU())\n",
    "dense_model2 = models.Dense(in_features=15000, out_features=1024,\n",
    "                           activation_function=nn.ReLU())\n",
    "\n",
    "normalize_model = models.Normalize()\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model, dense_model2, normalize_model])\n",
    "\n",
    "# freeze transformer layers of the model\n",
    "auto_model = model._first_module().auto_model\n",
    "for param in auto_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('pretrained_sentence_transformer_clinicalBertEmbeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('pretrained_sentence_transformer_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('pretrained_sentence_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(sentence_embeddings, sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings @ sentence_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df['notes'][:-1:len(df['notes'])//20]\n",
    "run_and_plot_se(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RUymE2l9GZfO"
   ],
   "name": "Kopie von Semantic Similarity with TF-Hub Universal Encoder",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1638696755621
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
