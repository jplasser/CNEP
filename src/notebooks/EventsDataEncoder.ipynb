{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "190cf566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "from collections import OrderedDict\n",
    "\n",
    "class VariationalDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies the same dropout mask across the temporal dimension\n",
    "    See https://arxiv.org/abs/1512.05287 for more details.\n",
    "    Note that this is not applied to the recurrent activations in the LSTM like the above paper.\n",
    "    Instead, it is applied to the inputs and outputs of the recurrent layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout: float, batch_first: Optional[bool]=False):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training or self.dropout <= 0.:\n",
    "            return x\n",
    "\n",
    "        is_packed = isinstance(x, PackedSequence)\n",
    "        if is_packed:\n",
    "            x, batch_sizes = x\n",
    "            max_batch_size = int(batch_sizes[0])\n",
    "        else:\n",
    "            batch_sizes = None\n",
    "            max_batch_size = x.size(0)\n",
    "\n",
    "        # Drop same mask across entire sequence\n",
    "        if self.batch_first:\n",
    "            m = x.new_empty(max_batch_size, 1, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        else:\n",
    "            m = x.new_empty(1, max_batch_size, x.size(2), requires_grad=False).bernoulli_(1 - self.dropout)\n",
    "        x = x.masked_fill(m == 0, 0) / (1 - self.dropout)\n",
    "\n",
    "        if is_packed:\n",
    "            return PackedSequence(x, batch_sizes)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class LSTMNew(nn.LSTM):\n",
    "    def __init__(self, *args, dropouti: float=0.,\n",
    "                 dropoutw: float=0., dropouto: float=0.,\n",
    "                 batch_first=True, unit_forget_bias=True, **kwargs):\n",
    "        super().__init__(*args, **kwargs, batch_first=batch_first)\n",
    "        self.unit_forget_bias = unit_forget_bias\n",
    "        self.dropoutw = dropoutw\n",
    "        self.input_drop = VariationalDropout(dropouti,\n",
    "                                             batch_first=batch_first)\n",
    "        self.output_drop = VariationalDropout(dropouto,\n",
    "                                              batch_first=batch_first)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Use orthogonal init for recurrent layers, xavier uniform for input layers\n",
    "        Bias is 0 except for forget gate\n",
    "        \"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            elif \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif \"bias\" in name and self.unit_forget_bias:\n",
    "                nn.init.zeros_(param.data)\n",
    "                param.data[self.hidden_size:2 * self.hidden_size] = 1\n",
    "\n",
    "    def _drop_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight_hh\" in name:\n",
    "                getattr(self, name).data = \\\n",
    "                    torch.nn.functional.dropout(param.data, p=self.dropoutw,\n",
    "                                                training=self.training).contiguous()\n",
    "\n",
    "    def forward(self, input, hx=None):\n",
    "        self._drop_weights()\n",
    "        self.flatten_parameters() \n",
    "        input = self.input_drop(input)\n",
    "        seq, state = super().forward(input, hx=hx)\n",
    "        return self.output_drop(seq), state\n",
    "\n",
    "class EventsDataEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=390, hidden_dim=512, lstm_layers=3,\n",
    "                 filter_kernels=[2,3,4], filters=100, output_dim=1024,\n",
    "                 add_embeds=True, embed_dim=700,\n",
    "                 dropout=0.3, dropout_w=0.2, dropout_conv=0.2):\n",
    "\n",
    "        #dim, batch_norm, dropout, rec_dropout, task,\n",
    "        #target_repl = False, deep_supervision = False, num_classes = 1,\n",
    "        #depth = 1, input_dim = 390, ** kwargs\n",
    "\n",
    "        super(EventsDataEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = lstm_layers\n",
    "        self.bidirectional = True\n",
    "\n",
    "        # some more parameters\n",
    "        self.dropout = dropout\n",
    "        self.rec_dropout = dropout_w\n",
    "        self.depth = lstm_layers\n",
    "        self.drop_conv = dropout_conv\n",
    "        self.num_classes = 1\n",
    "        self.output_dim = output_dim\n",
    "        self.add_embeds = add_embeds\n",
    "        self.embed_dim = embed_dim if add_embeds else 0\n",
    "\n",
    "        # define the LSTM layer\n",
    "        # in keras we have inputs: A 3D tensor with shape [batch, timesteps, feature]\n",
    "        # units: Positive integer, dimensionality of the output space. = dim=num_units=hidden_size\n",
    "        if self.layers >=2:\n",
    "            self.lstm1 = LSTMNew(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim,\n",
    "                                num_layers=self.layers-1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=self.bidirectional,\n",
    "                                batch_first=True)\n",
    "            self.do0 = nn.Dropout(self.dropout)\n",
    "            \n",
    "        # this is not in the original model\n",
    "        if self.layers >=2:\n",
    "            self.lstm2 = LSTMNew(input_size=self.hidden_dim*2,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "        else:\n",
    "            self.lstm2 = LSTMNew(input_size=self.input_dim,\n",
    "                                hidden_size=self.hidden_dim*2,\n",
    "                                num_layers=1,\n",
    "                                dropoutw=self.rec_dropout,\n",
    "                                dropout=self.rec_dropout,\n",
    "                                bidirectional=False,\n",
    "                                batch_first=True)\n",
    "        \n",
    "        # three Convolutional Neural Networks with different kernel sizes\n",
    "        nfilters= filter_kernels\n",
    "        nb_filters= filters\n",
    "\n",
    "        # 48 hrs of events data\n",
    "        L_out = [(48 - k) + 1 for k in nfilters]\n",
    "        maxpool_padding, maxpool_dilation, maxpool_kernel_size, maxpool_stride = (0, 1, 2, 2)\n",
    "        dim_ = self.embed_dim + int(np.sum([100 * np.floor(\n",
    "            (l + 2 * maxpool_padding - maxpool_dilation * (maxpool_kernel_size - 1) - 1) / maxpool_stride + 1) for l in\n",
    "                           L_out]))\n",
    "\n",
    "        self.cnn1 = nn.Sequential(OrderedDict([\n",
    "            (\"cnn1_conv1d\", nn.Conv1d(in_channels=self.hidden_dim*2, out_channels=nb_filters, kernel_size=nfilters[0],\n",
    "                                      stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                                      padding_mode='zeros')),\n",
    "            (\"cnn1_relu\", nn.ReLU()),\n",
    "            (\"cnn1_maxpool1d\", nn.MaxPool1d(kernel_size=2)),\n",
    "            (\"cnn1_flatten\", nn.Flatten())\n",
    "        ]))\n",
    "\n",
    "        self.cnn2 = nn.Sequential(OrderedDict([\n",
    "            (\"cnn2_conv1d\", nn.Conv1d(in_channels=self.hidden_dim * 2, out_channels=nb_filters, kernel_size=nfilters[1],\n",
    "                                      stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                                      padding_mode='zeros')),\n",
    "            (\"cnn2_relu\", nn.ReLU()),\n",
    "            (\"cnn2_maxpool1d\", nn.MaxPool1d(kernel_size=2)),\n",
    "            (\"cnn2_flatten\", nn.Flatten())\n",
    "        ]))\n",
    "\n",
    "        self.cnn3 = nn.Sequential(OrderedDict([\n",
    "            (\"cnn3_conv1d\", nn.Conv1d(in_channels=self.hidden_dim * 2, out_channels=nb_filters, kernel_size=nfilters[2],\n",
    "                                      stride=1, padding=0, dilation=1, groups=1, bias=True,\n",
    "                                      padding_mode='zeros')),\n",
    "            (\"cnn3_relu\", nn.ReLU()),\n",
    "            (\"cnn3_maxpool1d\", nn.MaxPool1d(kernel_size=2)),\n",
    "            (\"cnn3_flatten\", nn.Flatten())\n",
    "        ]))\n",
    "\n",
    "        self.encoder = nn.Sequential(OrderedDict([\n",
    "            (\"enc_relu\", nn.ReLU()),\n",
    "            (\"enc_fc1\", nn.Linear(dim_, self.output_dim)),\n",
    "            #(\"enc_fc1\", nn.Linear(dim_, dim_//2)),\n",
    "            #(\"enc_relu2\", nn.ReLU()),\n",
    "            #(\"enc_fc2\", nn.Linear(dim_//2, self.output_dim)),\n",
    "            #(\"enc_bn\", nn.BatchNorm1d(self.output_dim)),\n",
    "            (\"enc_layernorm\", nn.LayerNorm(self.output_dim)),\n",
    "            (\"enc_flatten\", nn.Flatten())\n",
    "        ]))\n",
    "\n",
    "        self.do2 = nn.Dropout(self.drop_conv)\n",
    "        #self.final = nn.Linear(dim_, self.num_classes)\n",
    "\n",
    "    def forward(self, inputs, embeds=None):\n",
    "        out = inputs\n",
    "        if self.layers >=2:\n",
    "            out, h = self.lstm1(out)\n",
    "            out = self.do0(out)\n",
    "        out, h = self.lstm2(out)\n",
    "        \n",
    "        pooling_reps = []\n",
    "        \n",
    "        pool_vecs = self.cnn1(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn2(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "        \n",
    "        pool_vecs = self.cnn3(out.permute((0,2,1)))\n",
    "        pooling_reps.append(pool_vecs)\n",
    "            \n",
    "        # concatenate all vectors\n",
    "        representation = torch.cat(pooling_reps, dim=1).contiguous()\n",
    "        out = self.do2(representation)\n",
    "        if embeds is not None:\n",
    "            out = torch.cat([out, embeds], dim=1)\n",
    "        encoding = self.encoder(out)\n",
    "        #out = self.final(out)\n",
    "\n",
    "        # return encoding in the shape of (output_dim)\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "727e0184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jplasser/miniconda3/envs/cnep/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = EventsDataEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e568ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventsDataEncoder(\n",
       "  (lstm1): LSTMNew(\n",
       "    390, 512, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True\n",
       "    (input_drop): VariationalDropout()\n",
       "    (output_drop): VariationalDropout()\n",
       "  )\n",
       "  (do0): Dropout(p=0.3, inplace=False)\n",
       "  (lstm2): LSTMNew(\n",
       "    1024, 1024, batch_first=True, dropout=0.2\n",
       "    (input_drop): VariationalDropout()\n",
       "    (output_drop): VariationalDropout()\n",
       "  )\n",
       "  (cnn1): Sequential(\n",
       "    (cnn1_conv1d): Conv1d(1024, 100, kernel_size=(2,), stride=(1,))\n",
       "    (cnn1_relu): ReLU()\n",
       "    (cnn1_maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (cnn1_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (cnn2_conv1d): Conv1d(1024, 100, kernel_size=(3,), stride=(1,))\n",
       "    (cnn2_relu): ReLU()\n",
       "    (cnn2_maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (cnn2_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (cnn3_conv1d): Conv1d(1024, 100, kernel_size=(4,), stride=(1,))\n",
       "    (cnn3_relu): ReLU()\n",
       "    (cnn3_maxpool1d): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (cnn3_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (encoder): Sequential(\n",
       "    (enc_relu): ReLU()\n",
       "    (enc_fc1): Linear(in_features=7500, out_features=1024, bias=True)\n",
       "    (enc_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (enc_flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (do2): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6bf7655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(10,48,390), torch.randn(10,700)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbee080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
